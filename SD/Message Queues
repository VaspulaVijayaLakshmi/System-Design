https://blog.algomaster.io/p/message-queues

Message queue allows systsem to communicate aynchroously.
It acts as an intermediary b/w 2 systems communicating woth each other


when the procucer of messages want sto produce indenpdenlty of the consumer consuming it.


This leads to DECOUPLED SYSTEM


Throttling: Message queues can help control the rate of message processing,
preventing consumers from being overwhelmed.

Less coupled ....

Core Components of a Message Queue

1. Producer/publisher - producing msgs wihtout bothering abt the consumer state
2. COsumer
3. Message - Queue - to store the messages prcused by producr which can be used by consumer indenpendently
4. Message - A unit of data , (payload) along with some metadata


5. Broker -  The software or service that manages the message queue, 
handles the delivery of messages, and ensures that messages are routed
correctly between producers and consumers.


Acknowledgment: Once the consumer processes the message, 
it may send an acknowledgment back to the broker, confirming that the 
message has been successfully handled.

Message Deletion: After acknowledgment, the broker removes the message from the queue 
to prevent it from being processed again.

We may not always delete the msgs in multi consumer enviroment, as these consumers may read data at
their own pace, so  offfset comes into pic
each comsumer has it won offset...
once a sgs is sucessfully delivered, offset is increased .



Types of Message Queues

1. P2P  model, messages are sent from one producer to one consumer.
Used when a message needs to be processed by a single consumer

2. Pub/SUB - messages are published to a topic, and multiple consumers can subscribe to 
that topic to receive messages.


3. Dead Letter Queue (DLQ) : A special type of queue where messages that cannot be processed (due to errors or retries) are sent.
Useful for troubleshooting and handling failed messages.


This is used in banking system....WHere msgs are retried when there are temporary failkures, so as to not 
make a double payment...



4. Priority Queue




In microsrvice architectue its services can communicate via MQ. 
It allows services to communicate async without blocking other operations.








Webhooks are event-driven, but events can fail — your consumer might be down, slow, or overloaded.
so we can use MQs


“Message queues decouple producers and consumers, improving reliability and scalability.”
“They help absorb traffic spikes and prevent downstream system overload.”
“MQs guarantee at-least-once or exactly-once delivery depending on config.”
“They support retries, DLQs, and message ordering where required.”
“Using MQs, we can handle temporary failures gracefully and ensure eventual consistency.”
“They’re great for asynchronous workflows like notifications, payments, and webhook delivery.”




Imagine Stripe sends a payment event:

Stripe → sends to your webhook queue.
Queue → stores message safely (Kafka / RabbitMQ).
Worker → reads event, updates DB, sends confirmation email.
If worker crashes → MQ keeps event → retried later.




Message Removal Behavior: Depends on MQ Type:

Traditional Message Queues (like RabbitMQ, SQS, ActiveMQ)
Yes, events are removed once consumed.

Flow:

Producer sends message → goes into queue.
Consumer reads message → processes it.
Consumer sends an acknowledgment (ACK) back to the queue.

MQ deletes the message permanently.
Example (RabbitMQ/SQS):
One message → one consumer → message gone after ACK.
If ACK not received → message re-queued (for retry).




Log-Based / Streaming Systems (like Kafka, Pulsar)

 No, events are not immediately removed after consumption.

Flow:

Kafka stores events in a log (partitioned and ordered).
Each consumer group maintains its own offset (i.e., “how far I’ve read”).
Kafka doesn’t delete events after consumption — it keeps them for a retention period (e.g. 7 days).

Why?

Different consumers might process the same topic independently (analytics, alerting, indexing).
Kafka needs to keep data so new consumers can replay old messages.

So Kafka acts more like a distributed event log than a queue.





Traditional MQ (RabbitMQ, SQS, etc.)

 Usually has same kind of consumers — doing the same type of work.
Think: multiple workers sharing a load.

Example:

You have a queue image-processing-queue.
3 consumers: Worker-1, Worker-2, Worker-3
All doing: resize → compress → upload.

Each message (job) goes to only one worker, so they can process in parallel.
Once one worker ACKs, message is deleted.

Traditional queues are for load distribution among same-type consumers.








Log-based MQ / Pub-Sub (Kafka, Pulsar, Pub/Sub)

 Can have different kinds of consumers — each doing different things with the same message.

Example:

A payment event is published to topic payment-events.

Different consumers:
Billing Service → updates ledger 
Notification Service → sends email 
Analytics Service → updates dashboard 
Fraud Detection Service → checks anomalies 


Each consumer group gets its own copy of every message and maintains its own offset.
The message stays in the topic until retention expires.


