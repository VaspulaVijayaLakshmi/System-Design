Function Requirements

Users should be able to create posts.
Users should be able to friend/follow people.
Users should be able to view a feed of posts from people they follow, in chronological order.
Users should be able to page through their feed.


NF:
scalable
relaible
highy available

Feed - read-heavy so it should be able to scale independently


eventual consistency -  we will pick No-sql DB - dynamo
 

____________________

Core enities : 


Key  - value pairs

Users:

UserId - User Name
       Posts
       Followers : List<Users>
       Following : List<Users>


Posts - Image/Video
        COmments
        LIkes
        Created On


Follow - UserFollowing (PK)      - reverse mapping as well -  
         FollowedBy (SK)

FOllow - FOllowing  - Graph Neo$j
we can traverse to the user's followers list and pull in 2nd degree connections for mutual recommnedation

Functionally, following or friending a person is establishing a relationship between two users. This is a many-to-many relationship, and we can model it as a graph.

_______________________



APIs:

POST: 
/Posts


GET
/feed -> List<Posts>    - Pagiates results


FOllowing and followers is many to many relationships

/follow-request
-> {} - OK


__________________________

Capacity Estimation:

100M users

DAU - 50M

Read : Write : 100:1

We post less compared to the posts we read

Posts - 50M * 5 - 250M posts

Read - on AVg each user reads 50-100 Posts
50M * 100 - 500M * 10 - 5Billion


Memory Estimation - 

1 Image - 200KB
Lets say 10M pictures everyday

10M * 200KB - ___GB
....

______________________
Design Diagram


User -> LB -> Post Service -> POSTS DB 

Feed -> userfollowing -> Follows Table


Follows Table - FollowId - FollowerId
                FollowerId - FOllowId

Dynamo DB maintains  GSI - Global Secondary Index – it’s a concept from NoSQL databases like DynamoDB.


________________________________________________

Now the question WHy we need FOllows Table?
instead of list ?


-> A celebrity could have 100M followers.
Storing a giant array in a single row/record = one huge blob.

-> List is hard to maintain - even if someone unfloows someone we need to update ists
this is burden for people who has lot of followers.


-> "Who are the 20 most recent people I followed?"
"Who are my followers (with pagination)?"

With a list, you’d have to load the entire blob 
With a Follows table, you can paginate/query efficiently.



-> Every new follow/unfollow = rewriting the giant list field.
In a Follows table, it’s just inserting/deleting one row. Much cheaper.


-> Distributed storage

In a sharded DB, you can’t easily split one giant array across shards.
But a Follows table with (followerId, followedId) can be sharded naturally by followerId.






__________________________

When a user posts a photo - all the followers should be able to see 

When a user wants to check  feed - all the people user is following 


SO when a user posts a pic - we fan out - to all the followers - send to everyone
but this is difficult for users with millions of followers


FAN -IN : WHen a user refreshes then we pull the chnages and update the feed.


OBSERVATION : Feed generation can be offline.

___________________________

So which we need to use?
Hybrid model would work


For users with large number of followers we can have Fan_IN that is when user refreshers we can send them.
Because we cant fanout to 10M users right.

FOr people following more people? their feed generation would be tougher - so we can use genertae and precompute the feed and store it and update overtime



How to precompute the feed ?

QUEUE + ASYNC FEED WORKERS

Since there can be a delay b/w when the opost is written and when its shown, we can leverage this to write it to an intermdeiate queue and a bunch of 
feed workers can read from these queue can update the feeds.

In this also making sure, we dont want these feed workers to update the feed of people - with celebirty

i.e, celebirty posts needs not be updated in the feed so we can maintain one flag  for feedworkers to skip these, because its a lot of writes
we can load into users feed on-demand.


Time stamp is major thing for feed geenrtion.



______________________________________________

How we can take care of DB hotspots?


Caching - 

we can keep a long time to live (TTL) on the posts and have our cache evict posts that are least recently used (LRU). 
As long as our cache is big enough to house most recent posts, the vast majority of requests to the Post Table will instead hit our cache


The biggest challenge with the Post Cache is it has the same hot key problem that the Post Table did! For the unlucky shard/partition that has multiple viral posts, 
the hosts that support it will be getting an unequal distribution of load (again) which makes this cache very hard to scale. 
Many of the hosts will be underutilized.

ORRR

Unlike the Distributed Post Cache solution above, we can choose to have multiple distinct caches that our readers can hit.
These cache instances don't need to coordinate. 
Instead of distributing the posts in our cache across the entire fleet, 
we can have multiple instances which can all service the same postID. 
This does mean we may have more requests that end up going to our database 
(for a very viral post, with N cache instances, we might have N requests to the database instead of 1 if we had sharded the cache by postID). 

But N requests is much, much smaller than the millions of requests we'd need to handle if we didn't have a cache in the first place.









