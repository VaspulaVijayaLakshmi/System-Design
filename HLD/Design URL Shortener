CAPACITY ESTIMATION : 


10M users

SO read to write ratio - 1:10

SO Daily Active USers (DAU) : 10M
And each user access 10 urls - 10M * 10 - 100M urls accessed per day

CACHE - Frequntely Accessed Urls

Writes - 1M - 1KB EACH   1024 bytes
so 1M - 1M*1KB per day

Total Memory per year - 365*1M*1KB 


__________________



Functional Requirements:

-> Users should be able to submit a long URL and receive a shortened version.

Optionally, users should be able to specify a custom alias for their shortened URL.
Optionally, users should be able to specify an expiration date for their shortened URL.


-> Users should be able to access the original URL by using the shortened URL.

_____________________

NF requiremnets : 

-> Avaiabilty
-> Consistency


this is Read heavy SYstem - then number of uniues url generated is way less than the no.of reads
So availability is IMP.

-> Scalable

-> Reliable - each short url should be mapped to one long url

-> replication and redundancy

___________________


SImple design 


USER -> LB -> URL SHORTENER SERVICE ->  DB

           -> Cache 


DB mapping:
short url -> long url


We need a random url geenrator  - which geenrated unique random letter.
Cache to store frequently Accessed urls


____________________


APIs :


Give long url to generate a short url

POST /urls
{
  "long_url": "https://www.example.com/some/very/long/url",
  "custom_alias": "optional_custom_alias",
  "expiration_date": "optional_expiration_date"
}

->
{
  "short_url": "http://short.ly/abc123"
}


Returns a shortened url


___________


GET:  Given a short url - return the long url

GET /{short_code}
-> HTTP 302 Redirect to the original long URL

_____________________




validate the long URL - This is to ensure that the URL is valid (there's no point in shortening an invalid URL)
and that it doesn't already exist in our system
(we don't want collisions).


301 - permanent Redirect
Browsers typically cache this response, meaning subsequent requests for the same short URL might go directly to the long URL, bypassing our server.


302 - temporary Redirect - browser dont cache

302 is better option because, 301 - browsers cache but these links have expirations


__________________




-> How to generate this 6-10 Short length random string?

*  Random Number Generator and Hash Function :
SHA1/MD5 algorithms

A random number (to avoid collisions).
A hash function (to generate a compact, unique code).
A short base encoding (Base62 → a-zA-Z0-9).


why do we ned base62 encoding after hash funtion

1. A hash function (SHA, MD5, polynomial hash, etc.) produces a big integer (or binary string).
   Example: MD5 gives a 128-bit hex string → 5d41402abc4b2a76b9719d911017c592.
   That’s too long and ugly for a short URL.

2. Need compact, human-friendly short codes
   We want a short identifier like abc123 not 5d41402abc....
   So we take the big hash number and compress it into fewer characters using Base62.


Why base62? It's a compact representation of numbers that uses 62 characters (a-z, A-Z, 0-9). 
The reason it's 62 and not the more common base64 is because we exclude the characters + and / since those are reserved for url encoding.


- COLLISIONS - IN HASH



 IMPROVISE:
__________

UNIQUE COUNTER WITH BASE ENCODING:


One way to guarantee we don't have collisions is to simply increment a counter for each new url. 
We can then take the output of the counter and encode it using base62 encoding to ensure it's a compacted representation.

Use a unique counter - redis is well suited.

Being single-threaded means Redis processes one command at a time, eliminating race conditions. 
Its INCR command is atomic, meaning the increment operation is guaranteed to execute completely without interference from other operations. 
This is crucial for our counter - we need absolute certainty that each URL gets a unique number, with no duplicates or gaps.



_______________________


How can we ensure that redirects are fast?

Redirects are fast - when given short url - return long url
Brute force - SCan through DB



1. Indexing: 

An index creates a separate, sorted list of our short URLs, each with a pointer to where the full information is stored in the main table

-> Primary Key: We should designate the short code as the primary key of our table. 
This automatically creates an index and ensures uniqueness.
By making the short code the primary key, we get the benefits of both indexing and data integrity,
as the database will enforce uniqueness and optimize queries on this field.


-> B-tree Indexing: Most relational databases use B-tree indexes by default.



2. Caching - Most frequently used url


3. CDNS - 

Fast Redirection (Edge Caching)

A short URL like sho.rt/abc123 → needs to redirect to the long URL.
Instead of all requests hitting your origin server, a CDN  can cache the redirect response (HTTP 301/302) at the edge.
That means users get lightning-fast redirects since the CDN is closer geographically.




So basically:

Read path (user clicks a short URL): CDN can help a lot → cache the 301/302 redirect.
Write path (user creates a short URL): CDN doesn’t help → must go to origin + DB.


_______________________



How can we scale to support 1B shortened urls and 100M DAU?


We can have sepaarte read service and write service so tht read service can scale independltly


Write opertion - Counter - We agreed on centralised redis global counter


-> Latancies - we can pregenerate URLS befor hand instead of generating at run time and use it thus saving 
            latencies and once we exhaust them we can again generate another set.

            Cache


________________



-> Database - SQL/ NO SQL
   Better choose Postgres


DATA replication
data backup - screenshots of data at regular itnervals

-> How to shard the DB? 

Range Based partitoning

We can have ???



_______________________


Users - submit long url and reeve short version



Back of the envelope calculation:




ApIs : 

Post request
Post long url and get short url

Validate the long url - check If URL already exists in db - bloom filter


URL may have expiration as well.


This system is read heavy 



Access 

Access the original url -> we have to scan entire databases -> which is very inefficient

We can create indexes - indexes based on what

Or we can use bloom filter - deterministic data structure - to identify if a element is present or not

We cannot conclusively say an element is present but we can say if it is not present..


Why we cannot say if it is present -> because of collisions
Bloom filter -> K hash fun^

K indices and we mark those indices.

If all k indices return 0, then it is not present else its present.



How does redirection happens?

Server response with HTTP redirect response


301  -  moved permanently -   browsers cache this response. Next request are directly redirected from the cache.

302 - moved temporarily - moved temporarily, browser do not cache this response.


302 is most preferred - because we can expire links 
                                     - if we need to  change/delete the short url




How to generate short url?

HashCode + Base62 Encoding


we could use a hash function like SHA-256 to generate a fixed-size hash code.
We can then take the output and encode it using a base62 encoding scheme and then take just the first N characters as our short code.



Why base62? It's a compact representation of numbers that uses 62 characters (a-z, A-Z, 0-9). The reason it's 62 and not the more common base64 is because we exclude the characters + and / since those are reserved for url encoding.


To handle collisions, implement a UNIQUE constraint on the short code column and retry with bounded attempts (e.g., max 3-5 retries).
Upon saving to the database, we'll get an error if the short code already exists.


Uniqueness

1. Primary Key: We should designate the short code as the primary key of our table. This automatically creates an index and ensures uniqueness. By making the short code the primary key, we get the benefits of both indexing and data integrity, as the database will enforce uniqueness and optimize queries on this field. 


Internally DBs use B_Tree Indexing
     how can we make  re-directs fast?



Redis cache - cache freq accessed urls 

Cache invalidation - LRU
CDNs - edge servers - Cache the urls.



DB - PostGres

Database replication 
Database Backup - periodically taking snapshot of our db.



Ready Heavy System - so we can separate concerns.

Read service - Handles redirects
Write service - handles creation of new short urls

Scale independently





